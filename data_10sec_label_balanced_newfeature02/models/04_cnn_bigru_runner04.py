# models/04_cnn_bigru_runner04.py
import torch
import torch.nn as nn

# Ù‡Ø§ÛŒÙ¾Ø±Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ (Runner 04 ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ L2 Ø±Ø§ Ø§Ø² Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†ÙØ¯)
CONFIG = {
    "epochs": 50,
    "batch_size": 32,
    "lr": 1e-3,
    "patience": 10,
    "weight_decay": 1e-4,   # â† ØªÙˆØ³Ø· R04 Ø¨Ù‡ Adam Ù¾Ø§Ø³ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    "dropout": 0.30,
    "rnn_hidden": 96,
    "rnn_layers": 2,        # Ø§Ú¯Ø± 1 Ú©Ù†ÛŒØŒ dropout Ø¯Ø§Ø®Ù„ÛŒ GRU ØºÛŒØ±ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯ (Ø±ÙØªØ§Ø± PyTorch)
    "rnn_dropout": 0.20,    # ÙÙ‚Ø· ÙˆÙ‚ØªÛŒ rnn_layers>1 Ø§Ø¹Ù…Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯
    "bidirectional": True
}

class CNN_BiGRU(nn.Module):
    """
    Frontend CNN Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ + BiGRU Ø¨Ø±Ø§ÛŒ ÙˆØ§Ø¨Ø³ØªÚ¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø¨Ù„Ù†Ø¯Ù…Ø¯Øª.
    ÙˆØ±ÙˆØ¯ÛŒ: (B, C=16, T=1500) â†’ Ø®Ø±ÙˆØ¬ÛŒ logits Ø¨Ø§ Ø´Ú©Ù„ (B, 1)
    """
    def __init__(self, in_ch=16, cfg: dict = None):
        super().__init__()
        cfg = cfg or CONFIG
        drop = float(cfg.get("dropout", 0.30))
        hid  = int(cfg.get("rnn_hidden", 96))
        nl   = int(cfg.get("rnn_layers", 2))
        rnn_do = float(cfg.get("rnn_dropout", 0.20))
        bi   = bool(cfg.get("bidirectional", True))

        # ---- CNN blocks ----
        self.block1 = nn.Sequential(
            nn.Conv1d(in_ch, 32, kernel_size=7, padding=3),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(2)             # 1500 -> 750
        )
        self.block2 = nn.Sequential(
            nn.Conv1d(32, 64, kernel_size=7, padding=3),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2)             # 750 -> 375
        )
        self.block3 = nn.Sequential(
            nn.Conv1d(64, 128, kernel_size=5, padding=2),
            nn.BatchNorm1d(128),
            nn.ReLU()
            # Ø·ÙˆÙ„ ØªÙˆØ§Ù„ÛŒ Ù‡Ù…ÛŒÙ†Ø¬Ø§ 375 Ù…ÛŒâ€ŒÙ…ÙˆÙ†Ù‡
        )

        # ---- BiGRU ----
        self.gru = nn.GRU(
            input_size=128, hidden_size=hid,
            num_layers=nl, batch_first=True,
            bidirectional=bi, dropout=(rnn_do if nl > 1 else 0.0)
        )
        rnn_out_ch = hid * (2 if bi else 1)  # Ú†ÙˆÙ† bidirectional=True Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 2*hidden Ù…ÛŒâ€ŒØ´ÙˆØ¯

        # ---- Head (temporal pooling + MLP) ----
        # Ø§Ø² Ù‡Ø± Ø¯Ùˆ Pooling (mean/max) Ø±ÙˆÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø²Ù…Ø§Ù†â€ŒØ¯Ø§Ø± GRU Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        head_in = rnn_out_ch * 2  # concat(mean, max)
        self.head = nn.Sequential(
            nn.Linear(head_in, 128),
            nn.ReLU(),
            nn.Dropout(drop),
            nn.Linear(128, 1)  # logits
        )

    def forward(self, x):  # x: (B, C, T)
        # CNN
        x = self.block1(x)                  # (B, 32, 750)
        x = self.block2(x)                  # (B, 64, 375)
        x = self.block3(x)                  # (B, 128, 375)

        # Ø¨Ø±Ø§ÛŒ GRU Ù†ÛŒØ§Ø² Ø¨Ù‡ (B, T, F) Ø¯Ø§Ø±ÛŒÙ…
        x = x.transpose(1, 2)               # (B, 375, 128)

        # GRU
        y, _ = self.gru(x)                  # (B, 375, rnn_out_ch)

        # Temporal pooling
        y_mean = y.mean(dim=1)              # (B, rnn_out_ch)
        y_max, _ = y.max(dim=1)             # (B, rnn_out_ch)
        z = torch.cat([y_mean, y_max], dim=1)  # (B, 2*rnn_out_ch)

        # Head â†’ logits
        logits = self.head(z)               # (B,1)
        return logits

def build_model(input_channels=16, seq_len=1500):
    # seq_len Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ø¯Ø§Ø±Ø¯ ÙˆÙ„ÛŒ Ø§Ù…Ø¶Ø§ Ø±Ø§ Ø¨Ø§ Ø±Ø§Ù†Ø± Ø³Ø§Ø²Ú¯Ø§Ø± Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ…
    return CNN_BiGRU(in_ch=input_channels, cfg=CONFIG)

# ---- Ø§Ø¬Ø±Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… ÙØ§ÛŒÙ„ Ù…Ø¯Ù„ (PyCharm Run) ----
if __name__ == "__main__":
    import os, sys, argparse
    ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    sys.path.insert(0, ROOT)

    # ğŸ”§ Ø±Ø§Ù†Ø± 04 (Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø·Ø§Ø¨Ù‚ Ù†Ø§Ù… ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ Ø³Ø§Ø®ØªÛŒ):
    import runners.R04_runner_acc_constrained_wd as runner
    # ÛŒØ§ Ø§Ú¯Ø± Ø¨Ø§ Ø­Ø±ÙˆÙ Ú©ÙˆÚ†Ú© Ø°Ø®ÛŒØ±Ù‡ Ú©Ø±Ø¯Ù‡â€ŒØ§ÛŒ:
    # import runners.runner_04_acc_constrained_wd as runner

    p = argparse.ArgumentParser()
    p.add_argument("--epochs", type=int, default=None)
    p.add_argument("--batch_size", type=int, default=None)
    p.add_argument("--lr", type=float, default=None)
    p.add_argument("--patience", type=int, default=None)
    p.add_argument("--seed", type=int, default=42)
    args = p.parse_args()

    runner.run_with_model_path(
        __file__,
        epochs=args.epochs,
        batch_size=args.batch_size,
        lr=args.lr,
        patience=args.patience,
        seed=args.seed
    )
